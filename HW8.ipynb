{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d8a4612f",
   "metadata": {},
   "source": [
    "# Homework 8: (a) Posterior Predictive Distributions<br> and (b) Missing Data Imputation\n",
    "\n",
    "### 1. Describe how the posterior predictive distribution is created for mixture models \n",
    "\n",
    "### 2. Describe how the posterior predictive distribution is created in general\n",
    "\n",
    "### 3. Have glance through [this](https://www.pymc.io/projects/examples/en/latest/case_studies/Missing_Data_Imputation.html) and then describe how, if you were doing a regression of $y$ on $X$ but $X$ had some missing values, you could perform a Bayesian analysis without throwing away the rows with missing values in $X$\n",
    "\n",
    "- **Hint: latent variables $v$ indicating the subpopulation are competely missing values that we simply treat as paramters to be inferred though posterior analysis... the same sort of thing can be done with missing values in data that need to be imputed... we should just be careful about the MCAR assumption...**\n",
    "\n",
    "### 4. Work on your course project\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "990df38d",
   "metadata": {},
   "source": [
    "1. For posterior prediction distribution in mixture models, first, the posterior distribution of the parameters in the mixture model need to be calculated using the observed data. The parameters of the mixture model also includes mixture weights. Then, posterior predictive distribution for a new data point is computed through integrating the posterior distribution of the parameters, weighted by their posterior probabilities to obtain the final posterior prediction distribution. It is worthnoticing that the integration must account for each model being mixed in the mixture model. \n",
    "2. For posterior prediction distribution in general, It is calculated through integrating the likelihood of the new data point given the parameters times the posterior distribution of the parameters given the observed data, then averaging the predictive distribution of new data points over all possible values of the parameters weighted by their posterior probabilities. \n",
    "3. When dealing with missing data in X, treating the missing data as latent variables that can be estimated through the Bayesian process. the Bayesian analysis directly imputes the missing values through the process of MCMC sampling as it enable us to approximate the posterior distributions of the missing values along with the regression coefficients. Then the MCMC algorithm generates multiple possible values for the missing data."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
